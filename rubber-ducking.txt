I am sure I am going to regret some of this file structure lol 

ok so I can use some sample images to detect lying and other emotional intelligence questions based on pictures 
	I can probably get them by looking back as the Unanimous Paper on EQ (https://unanimous.ai/wp-content/uploads/2018/09/Amplifying-Social-Intelligence-IEEE-ai4i-2018.pdf)

let's try to update the rank of the questions based on their votes 
	this is the way you sort an array of objects by value (https://www.javascripttutorial.net/array/javascript-sort-an-array-of-objects/)
		I also checked that this works in the browser
	now I just have to do it in state 

now that I've hooked up Firebase (get it, "hooked" up ahahha), let's figure out the optimal JSON structure
	uhm, I guess I have not figured out how to update Firebase from the app lol 
	how do I update the rank of the questions
		I should probably just sort them by value
		wait, it's already there in the code! 
	maybe I should calculate the score by adding the scores from all participants
		Yea, that makes sense  

	firebase {
		combo {
			pictureA: "dogA_id",
			pictureB: "dogB_id",
			features: {
				"preset_feature_A": {
					"score": {
						0: 0
						1: .2
						2: .3
					}
					"weight": 12
				},
				"generated_feature_A": {
					"score": {
						0: 0
						1: .5
						2: .2
					}
					"weight": 11
				},
			}
		}
	}

let's see, how do I best leverage the onChange on the range input
	I should probably do this when I move everything to the new view
	Yea, bc new view --> table with the input 
	I should probably implement this rn and then just move the logic to the new view when I get to it
	hook + push the object on submit vs. update Firebase continously 
		The issue with updating Firebase right away is that I'd have to somehow track who voted for what 
			I guess I could use the push.key trick and save that into state and just update that key all the time
			{ "user_id": vote } vs { "key": {"user_id": vote } }


let's create the round robin system 
	the pic pair is going to be in the JSON already 
		I'm going to generate the base JSON with a python script
	
Ok the key now is to do a limited view change
	Thinking of holding a title in the middle and then rendering the other components invisible
	I wonder how the original Flock paper did this
		"Flock asks crowd members to guesswhich of two examples is from a positive class and which isfrom the negative class, then write a reason why. These rea-sons become features: Flock automatically clusters the rea-sons, then recruits crowds to normalize each cluster and pro-duce features. These features are then used by the crowd toannotate each example."
		"Flock trains multiple models with different fea-ture subsets. It does so to show the user the performance of multiple prediction methods on the test set. These models in-clude Crowd prediction(a baseline asking workers directlyto guess the correct label for the example), ML with off-the-shelf(the chosen machine learning model using only out-of-the-box features such as n-grams), ML with crowd(the cho-sen machine learning model using only crowd features), or Hybrid(the full Flock model using both machine and crowdfeatures)."
		"Previous research on analogical encoding has found thatwhen considering single examples, people tend to focus onsurface-level details, but when they compare examples, theyfocus on deeper structural characteristics"
		"Flock launches 100c omparison tasks with three workers each per dataset, result-ing in 300 nominated features for about six cents per label ($20 total)."
	Ah ok, so they have one task to generate features, and one task to vote on them
		They are two separate tasks
		"The features have considerable overlap, and manual cat-egorization suggested that the 300 nominations typically clus-tered into roughly 50 features."
		"First, the system splits each responseinto multiple suggestions (e.g. by sentence, newlines, andconjunctions such as “and”). The system then performsk-means clustering (k= 50) using tf-idf weighted bigram text4 features. With these clusters in hand, Flock launches anothertask to CrowdFlower showing workers one cluster at a timeand asking them to summarize each into a single represen-tative question (or feature) that has a yes or no answer (e.g.,“Is this person shifting their eyes a lot?”). Three candidatefeatures are generated for each cluster."

MapReduced version
	Feature Generation 
		Should we do 2 different dogs and 1 that is similar to at least one of them? 
		Similarity + Difference
			Ask about similarities 
			Ask about differences 
		Cluster
			Basic n-gram stuff 
		Extract top 3 summary features 
	Feature Evaluation
		Rank is individual 
		Scoring is continous 

ok so let's figure out the sequence to pull of the rewrite
	I need to probably make separate pages, so that each link links to a different task 
	the features generated don't need to be linked by users 
		they can be just a part of JSON, a separte child
	then from that child I build a page where it shows the n-gram and the user submist the summary 
		the summary features need to be binary 
		then voting happens, which is how the top 3 gets selected
			which means I have to save this per user, or at least find a way to maintain the voting
				I can just not show current votes to the user and have them vote without registering who they are
		the summaries are saved on a new child 
	after clustering, I move on to the feature evalution 
		both rank and scoring need to be attached to an individual user 

ok so let's structure this DB
	firebase {
		suggestions: {
			idA: "suggestion from user A",
			idB: "suggestion from user B"
		},
		clusters: {
			clusterA: {
				suggestions: [ngramA, ngramB],
				summaries: {
					summary_id_1 {
						id_a: "summarizing cluster A",
						vote: 0
					},
					summary_id_2 {
						id_a: "summarizing cluster A",
						vote: 0
					}
				}

			}
		},
		combo {
			pictureA: "dogA_id",
			pictureB: "dogB_id",
			features: {
				"summary_id_1": {
					"score": {
						0: 0
						1: .2
						2: .3
					}
					"weight": {
						0: 0
						1: .2
						2: .3
					}
				},
				"summary_id_2": {
					"score": {
						0: 0
						1: .5
						2: .2
					}
					"weight": {
						0: 0
						1: .2
						2: .3
					}
				},
			}
		}
	}

ok so I'm at the suggestions page
	I already implemented the form to submit the suggestion, now I just have to do voting
	I can probably re-implement the logic from the v1
	The voting here though is not attached to the user, it's more like a usual upvote/downvote mechanism
		This means I need to add a "votes" value-key pair to each suggestion child
	I keep thinking that I should have separate phases for submitting and voting
		I am so dumb lol
		I already implemented this!!
	Why is it not updating?
		bc I was sorting the snapshots as opposed to the actual object
	Now I just need to limit the voting to just once per item
		I can disable the button for that vote
		how do I do this without having to set up a hook or a global property
		boom!

now I let's do the eval page
	mostly it's the same as the v1, just removing the option
	ok so I probalby don't need to change that much logic, bc I can set up the features to be evaluted based on teh results from the summary task 
		I'll automate this some day 
	ok so assume you already have the right features for each pair of dog pictures, what do you need to change? 
		both rank and scoring need to be attached to each user
	do I want to structure the data to be feature centric by having user-identified updates to the children of the feature? 
		Or do I want to make it user centric? 
		well, at a basic level it'd make it a lot easier to have this be pair centric to build the graph afterwards 
	uhm, so when the user submits, they are submitting a score and a rank 
		obviously score comes first, replicating the staging process that we have in the summary task 
		so all I need to do is restructure "weight" to be like "score" and similarly attach the value to the user-id
			the order somewhat doesn't matter as long as I have the id
	gosh, wouldn't be great if this was a carosel type thing
		#scope-creep
	ok so now even the next function operates properly

ok so let's see, where am I now? 
	I have to create a closing tastement for every task
		That's not too bad, especially bc I need to start with task 1

ok we are back
	so, I already implemented the two phases of Task 2, so at this point I just have to just restructure it so that it's based on clusters
	I need to update the structure of the Firebase JSON, and then ensure the updates are flowing smoothly 
		cluster1 {
			suggestions {
				0: "lorem ipsum"
			}
			summaries {
				summary_A {
					userID: userID
					text: "lorem ipsum"
					votes: 0
				}
				summary_B {
					userID: userID
					text: "lorem ipsum"
					votes: 0
				}
			}
		}
	should voting the top 3 features happend after every cluster?
		probably
	let's start by checking if I can move across clusters easily
		woot woot!
	now let's see if I can uplaod the summaries correctly
		uploading works, but now I have to do the voting correctly
		ok so now I have to update the votes correctly
	nice, so now let's go to the top items from the cluster

Duplicate checker
	it should be pretty easy
	I need to loop through all the Firebase answers so far
		let's start with this
	I get all the answers and remove filler words like "the", "are", "dogs", and "both"
	then I run the same function on the submitted answer and check in whether any key terms left are already in the list
	this shouldn't be too hard, but I might have to read up on some NLP shit
	ok so this works, but maybe reduce the answers into a single large array to check for duplicates is not the right appraoch
		after all, you shouldn't be penalized for using the word "long" if it's referring to a different body part
		so then I should make a regular loop that just terminates if too many words are included
	wow, so update the hook doesn't work within this while loop for some reason lol
		gotta implement some crappy solution
	I want to show them the prior answers, which shouldn't be hard
		I worry I'll upset them though if they try for like 30m and don't come up with anything new
		I could show them different dogs after like 5 attempts
			yea, and then reset after 5

clustering
	first, I need to re-run task 1
		let's download all the prior responses
		then I'll narrow it to the last 50 bc they came from the 10 Master Turkers
		and then I'll do a clean slate
	why isn't it updating on vercel?
		ok now it works
		so strange lol
	ok back to clustering
		now I'm going to take the good suggestions and run the n-gram script
	what a win for real time patching ahah
	ok so back to clustering now
		this mofo ain't working properly lol
		I mean, the DB scan is working right, but some of these features include the verbs
		I need to extrac key words maybe?
			that's what the stopwords nltk error is about!!
				great way of debugging through permissions!
		ok this is starting to make more sense

ok let's do this: Task 3
	first, let's figure out the features from the clusters
		let's first run an experiment with the new suggestions
			same fur color
			same size
			patches? 
			droopy face
			length of neck
			thin mid-section
			relaxed ears
			floppy ears
			looseness of fur
			stomach curvature
			length tails
			length of jaw
			ferociousness 
			curl of tail
			skin around nose
			teeth
		yes, let's try these
			let's generate them with a script
	also, rn it's 5 dogs but it ends up being 20 comparisons
		should I do more?
			Nah, not yet
	ok so we got the features, but now let's add some anti-trolling
		I could make them answer each question separately
			that way the next button only shows up at the end
		ok, fixed the default value so it still moves
		I could do question by question, with some duplicates as the attention check
			Yea, and the whole thing has to start over if they fail at answering in the same exact way
			This is easier said than done ahah
			also, the Next button should only show up at the end
			maybe I should use UseEffect to initialize the list of features and then have a hook that just loops through them
			oh yea, wait it's that easy bc I can just figure out the keys each time
				nice. Not super-clean but not dirty either
			now I have to create the right event for the NextFeature button to show up
				I really don't want to have to create a separate hook for this
				boom!
			nice, so now everything is place to implement the attention check
				ok let's do this
				how should I structure this? 
					I could initialize and select some random int within the number of features where I inject a repeated question
						then I check double check the values
							I feel like this is not the hard part
					yea, I could select some random int
						actually, select a random feature and then a random time to ask it again
						and then through conditinal checking I inject it again!!
							let's try it
						so close: you've got this
				ok so now you are accessing firebase effectively
			this should be a simple comparison
				oh shit, what if I get the same issue about internal state updates like I did last time...
					wait jk it just worked!
				now the issue is enabling the person to keep going
					should I make a new hook where the status is passed?
				nice! now it works
					let's just add attention checks to the script

ok, so first let's fix this bug
	for some reason, past pair0 it's only showing them the rank features as opposed to scoring
		was this for all of them?
			yes
	I wonder if it's bc I'm not switching stages properly
		let's check the logic when the dogPair switches
		weird...it just worked
			might just have to re-run it lol

ok so let's implement the progress bar
	go React Boostrap, so much easier lol

time to do the graph
	let's get this d3 thing going on
	let's actually take the time to learn this

let's figure out this PCA ranking
	ok so now that I talked to Daniel this makes more sense
		breed_name is the last value in the array
		multiple samples for each breed
	first, ima average the multiple samples
		heck yes
	then ima go through each pair and compute the Eucledian distance
		now the key here is to run through all the pairs
	then ima rank the pairs by Eucledian distances and select the top 50
	 	top 50 means 2450 (50 * 49) pair-wise comparisions lol
	 		this is a lot of comparisions, might have to trim it to just 5
	 	actually, it's just 50 pairs, not 50 dogs so we are good lol

ok so first let's re-run Task 1
	how should I do this? 
	I have the top 50 pairs, so I just have to break that down into the actual dogs
	I can likely update the base_json script and generate the right sequence that way
	actually, this is probably easier bc I can just append this to the script

TO-DO sidenote
	build the graph automatically
	might be good to have a survey at the end
	let's not forget about the crypto mining in the background






